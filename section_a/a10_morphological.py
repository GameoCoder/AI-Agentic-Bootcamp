"""
a10_morphological.py
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Morphological analysis pipeline:
  1. Prompts the Ollama LLM to decompose Hindi words into morphemes.
  2. Saves the output as JSONL (one analysis per line).
  3. Provides a stub `BiLSTMTagger` class skeleton for training on the
     synthetic data (full training requires PyTorch + labeled data).

Usage:
    python section_a/a10_morphological.py
    python section_a/a10_morphological.py --words "‡§ñ‡§æ‡§®‡§æ,‡§ú‡§æ‡§®‡§æ,‡§™‡§¢‡§º‡§æ‡§à,‡§¨‡§ö‡•ç‡§ö‡§æ"
"""

import json
import re
import sys
from pathlib import Path
import click
from tqdm import tqdm

sys.path.insert(0, str(Path(__file__).parent.parent))
import config
from utils.ollama_client import ollama_chat

OUTPUT_JSONL = config.DATA_DIR / "morphological_data.jsonl"

SAMPLE_WORDS = [
    "‡§ñ‡§æ‡§®‡§æ", "‡§™‡§æ‡§®‡•Ä", "‡§ú‡§æ‡§®‡§æ", "‡§Ü‡§®‡§æ", "‡§™‡§¢‡§º‡§æ‡§à", "‡§≤‡§ø‡§ñ‡§æ‡§à", "‡§¨‡§ö‡•ç‡§ö‡§æ", "‡§≤‡§°‡§º‡§ï‡•Ä",
    "‡§ï‡§ø‡§§‡§æ‡§¨", "‡§∏‡•ç‡§ï‡•Ç‡§≤", "‡§∏‡§∞‡§ï‡§æ‡§∞", "‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§™‡§ï", "‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§≤‡§Ø", "‡§∏‡•Å‡§Ç‡§¶‡§∞", "‡§ñ‡•Å‡§∂‡•Ä",
    "‡§®‡§æ‡§ö‡§®‡§æ", "‡§ó‡§æ‡§®‡§æ", "‡§∏‡§´‡§≤‡§§‡§æ", "‡§Ö‡§∏‡§´‡§≤‡§§‡§æ", "‡§¨‡•á‡§∞‡•ã‡§ú‡§ó‡§æ‡§∞‡•Ä", "‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞‡§§‡§æ",
    "‡§≠‡§æ‡§∞‡§§‡•Ä‡§Ø", "‡§π‡§ø‡§Ç‡§¶‡•Å‡§∏‡•ç‡§§‡§æ‡§®", "‡§Æ‡§π‡§æ‡§∞‡§æ‡§∑‡•ç‡§ü‡•ç‡§∞", "‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä‡§µ‡§æ‡§≤‡§æ", "‡§∏‡§Æ‡§ù‡§¶‡§æ‡§∞",
    "‡§≤‡§°‡§º‡§ï‡§æ", "‡§ò‡§∞", "‡§ï‡§æ‡§Æ", "‡§ú‡§º‡§∞‡•Ç‡§∞‡§§", "‡§∏‡§Æ‡§ù‡§®‡§æ", "‡§¨‡•ã‡§≤‡§®‡§æ", "‡§¶‡•á‡§ñ‡§®‡§æ",
]


def analyze_word(word: str) -> dict:
    """Ask LLM to morphologically analyze a Hindi word."""
    prompt = (
        f"‡§π‡§ø‡§®‡•ç‡§¶‡•Ä ‡§∂‡§¨‡•ç‡§¶ '{word}' ‡§ï‡•á morphemes (‡§â‡§™‡§∏‡§∞‡•ç‡§ó, ‡§Æ‡•Ç‡§≤, ‡§™‡•ç‡§∞‡§§‡•ç‡§Ø‡§Ø) ‡§¨‡§§‡§æ‡§á‡§è‡•§ "
        "JSON format ‡§Æ‡•á‡§Ç ‡§¶‡•á‡§Ç:\n"
        '{"word": "<word>", "root": "<root>", "prefix": "<prefix_or_empty>", '
        '"suffix": "<suffix_or_empty>", "meaning": "<brief meaning in Hindi>"}'
    )
    response = ollama_chat(prompt)
    # Extract JSON from response
    json_match = re.search(r"\{.*\}", response, re.DOTALL)
    if json_match:
        try:
            data = json.loads(json_match.group())
            data["word"] = word  # ensure correct word
            return data
        except json.JSONDecodeError:
            pass
    return {
        "word": word,
        "root": word,
        "prefix": "",
        "suffix": "",
        "meaning": response[:100],
    }


@click.command()
@click.option("--words", default=None, help="Comma-separated list of words to analyze")
@click.option("--from-corpus", is_flag=True, help="Sample words from unigram list")
@click.option("--sample-size", default=100, show_default=True)
def main(words: str | None, from_corpus: bool, sample_size: int):
    if words:
        word_list = [w.strip() for w in words.split(",") if w.strip()]
    elif from_corpus and config.UNIGRAMS_JSON.exists():
        vocab = list(json.loads(config.UNIGRAMS_JSON.read_text(encoding="utf-8")).keys())
        word_list = [w for w in vocab[:sample_size] if len(w) > 2]
    else:
        word_list = SAMPLE_WORDS
        print(f"üìù Using {len(word_list)} built-in sample words")

    results = []
    for word in tqdm(word_list, desc="Morphological analysis"):
        analysis = analyze_word(word)
        results.append(analysis)

    OUTPUT_JSONL.parent.mkdir(parents=True, exist_ok=True)
    with open(OUTPUT_JSONL, "w", encoding="utf-8") as f:
        for r in results:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"‚úÖ Morphological data saved ‚Üí {OUTPUT_JSONL}  ({len(results)} entries)")
    print("\nSample output:")
    for r in results[:3]:
        print(f"  {r}")


if __name__ == "__main__":
    main()
