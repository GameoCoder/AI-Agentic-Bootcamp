"""
c1_chatbot.py
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Hindi Conversational Chatbot using LangChain + Ollama.
Features:
  - Persistent conversation memory (last N turns)
  - Tool: Wikipedia lookup (Hindi)
  - Tool: Weather (OpenWeatherMap, if API key configured)
  - Responds in Hindi

Usage:
    python section_c/c1_chatbot.py
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))
import config
from utils.ollama_client import ollama_chat

from langchain_ollama import ChatOllama
from langchain.memory import ConversationBufferWindowMemory
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain import hub
import requests
import wikipedia


# ‚îÄ‚îÄ Tools ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def wikipedia_search(query: str) -> str:
    """Search Hindi Wikipedia for a query."""
    try:
        wikipedia.set_lang("hi")
        return wikipedia.summary(query, sentences=3)
    except Exception as e:
        return f"Wikipedia ‡§∏‡•á ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä: {e}"


def weather_tool(city: str) -> str:
    """Get current weather for a city."""
    if not config.OPENWEATHER_API_KEY:
        return ollama_chat(f"{city} ‡§ï‡•á ‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¶‡•á‡§Ç‡•§")
    try:
        url = (
            f"http://api.openweathermap.org/data/2.5/weather"
            f"?q={city}&appid={config.OPENWEATHER_API_KEY}&units=metric&lang=hi"
        )
        data = requests.get(url, timeout=10).json()
        desc = data["weather"][0]["description"]
        temp = data["main"]["temp"]
        return f"{city} ‡§Æ‡•á‡§Ç ‡§Ö‡§≠‡•Ä: {desc}, ‡§§‡§æ‡§™‡§Æ‡§æ‡§® {temp}¬∞C"
    except Exception as e:
        return f"‡§Æ‡•å‡§∏‡§Æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§®‡§π‡•Ä‡§Ç: {e}"


TOOLS = [
    Tool(name="Wikipedia", func=wikipedia_search,
         description="‡§π‡§ø‡§®‡•ç‡§¶‡•Ä Wikipedia ‡§™‡§∞ ‡§ï‡•Å‡§õ ‡§ñ‡•ã‡§ú‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§"),
    Tool(name="Weather", func=weather_tool,
         description="‡§ï‡§ø‡§∏‡•Ä ‡§∂‡§π‡§∞ ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§ú‡§æ‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§ Input: city name."),
]


# ‚îÄ‚îÄ Agent ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def build_agent() -> AgentExecutor:
    llm = ChatOllama(
        base_url=config.OLLAMA_BASE_URL,
        model=config.OLLAMA_MODEL,
        temperature=0.4,
    )
    memory = ConversationBufferWindowMemory(
        memory_key="chat_history",
        k=10,
        return_messages=True,
    )
    try:
        prompt = hub.pull("hwchase17/react-chat")
    except Exception:
        # Fallback if hub unavailable
        from langchain.prompts import PromptTemplate
        prompt = PromptTemplate.from_template(
            "‡§§‡•Å‡§Æ ‡§è‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó‡•Ä ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä chatbot ‡§π‡•ã‡•§ ‡§π‡§Æ‡•á‡§∂‡§æ ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•ã‡•§\n"
            "Chat History: {chat_history}\n"
            "Question: {input}\n"
            "Thought: {agent_scratchpad}"
        )
    agent = create_react_agent(llm, TOOLS, prompt)
    return AgentExecutor(
        agent=agent,
        tools=TOOLS,
        memory=memory,
        verbose=True,
        handle_parsing_errors=True,
        max_iterations=5,
    )


def simple_chat_loop():
    """Simple fallback using direct Ollama calls with manual memory."""
    history: list[dict] = []
    print("ü§ñ ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä ‡§ö‡•à‡§ü‡§¨‡•â‡§ü ‡§∂‡•Å‡§∞‡•Ç ‡§π‡•ã ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¨‡§æ‡§π‡§∞ ‡§®‡§ø‡§ï‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è 'quit' ‡§ü‡§æ‡§á‡§™ ‡§ï‡§∞‡•á‡§Ç‡•§\n")
    SYSTEM = (
        "‡§§‡•Å‡§Æ ‡§è‡§ï ‡§â‡§™‡§Ø‡•ã‡§ó‡•Ä ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä ‡§≠‡§æ‡§∑‡§æ ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•ã‡•§ "
        "‡§π‡§Æ‡•á‡§∂‡§æ ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§î‡§∞ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§ú‡§µ‡§æ‡§¨ ‡§¶‡•ã‡•§"
    )
    import requests as req, json

    while True:
        user_input = input("‡§Ü‡§™: ").strip()
        if user_input.lower() in ("quit", "exit", "‡§¨‡§æ‡§π‡§∞"):
            print("‡§®‡§Æ‡§∏‡•ç‡§§‡•á! üôè")
            break

        history.append({"role": "user", "content": user_input})
        payload = {
            "model": config.OLLAMA_MODEL,
            "messages": [{"role": "system", "content": SYSTEM}] + history[-12:],
            "stream": False,
        }
        resp = req.post(config.OLLAMA_CHAT_ENDPOINT, json=payload, timeout=60)
        reply = resp.json().get("message", {}).get("content", "")
        history.append({"role": "assistant", "content": reply})
        print(f"Bot: {reply}\n")


def main():
    print("=" * 50)
    print("   ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä AI ‡§ö‡•à‡§ü‡§¨‡•â‡§ü (Powered by Ollama qwen2:0.5b)")
    print("=" * 50)
    try:
        agent = build_agent()
        print("‚úÖ LangChain Agent ready. Type 'quit' to exit.\n")
        while True:
            user = input("‡§Ü‡§™: ").strip()
            if user.lower() in ("quit", "exit"):
                break
            result = agent.invoke({"input": user})
            print(f"Bot: {result['output']}\n")
    except Exception as e:
        print(f"‚ö†  LangChain agent failed ({e}), using simple mode.")
        simple_chat_loop()


if __name__ == "__main__":
    main()
